{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "26b64a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [05:39<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [[-5.55111500e-17 -3.33066900e-16  2.22044600e-16]\n",
      " [ 8.42128448e-02  3.28181658e-02  9.57672840e-01]\n",
      " [ 7.53596018e-02  1.40758245e-02  1.92077186e+00]\n",
      " ...\n",
      " [ 3.12281343e+02  2.51655885e+01  2.72333384e+02]\n",
      " [ 3.12281343e+02  2.51655885e+01  2.72333384e+02]\n",
      " [ 3.12281343e+02  2.51655885e+01  2.72333384e+02]]\n",
      "avg_mse scores 73.1011901704272\n",
      "[[-5.55111500e-17 -3.33066900e-16  2.22044600e-16]\n",
      " [ 8.42128448e-02  3.28181658e-02  9.57672840e-01]\n",
      " [ 7.53596018e-02  1.40758245e-02  1.92077186e+00]\n",
      " ...\n",
      " [ 3.12281343e+02  2.51655885e+01  2.72333384e+02]\n",
      " [ 3.12281343e+02  2.51655885e+01  2.72333384e+02]\n",
      " [ 3.12281343e+02  2.51655885e+01  2.72333384e+02]] (801, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import cv2, skimage, os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class OdometryClass:\n",
    "    def __init__(self, frame_path):\n",
    "        self.frame_path = frame_path\n",
    "        self.frames = sorted(glob(os.path.join(self.frame_path, 'images', '*')))\n",
    "        with open(os.path.join(frame_path, 'calib.txt'), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.focal_length = float(lines[0].strip().split()[-1])\n",
    "            lines[1] = lines[1].strip().split()\n",
    "            self.pp = (float(lines[1][1]), float(lines[1][2]))\n",
    "            \n",
    "        with open(os.path.join(self.frame_path, 'gt_sequence.txt'), 'r') as f:\n",
    "            self.pose = [line.strip().split() for line in f.readlines()]\n",
    "        \n",
    "        ###### Initialze #####\n",
    "        self.img = {}\n",
    "        initialize = np.array(self.pose[0]).reshape(3,4).astype('float64') \n",
    "        self.current_R = initialize[:3,:3]\n",
    "        self.current_t = initialize[:,3].reshape(3,1)\n",
    "        \n",
    "    def imread(self, fname):\n",
    "        \"\"\"\n",
    "        read image into np array from file\n",
    "        \"\"\"\n",
    "        return cv2.imread(fname, 0)\n",
    "\n",
    "    def imshow(self, img):\n",
    "        \"\"\"\n",
    "        show image\n",
    "        \"\"\"\n",
    "        skimage.io.imshow(img)\n",
    "\n",
    "    def get_gt(self, frame_id):\n",
    "        pose = self.pose[frame_id]\n",
    "        x, y, z = float(pose[3]), float(pose[7]), float(pose[11])\n",
    "        return np.array([[x], [y], [z]])\n",
    "\n",
    "    def get_scale(self, frame_id):\n",
    "        '''Provides scale estimation for mutliplying\n",
    "        translation vectors\n",
    "        \n",
    "        Returns:\n",
    "        float -- Scalar value allowing for scale estimation\n",
    "        '''\n",
    "        prev_coords = self.get_gt(frame_id - 1)\n",
    "        curr_coords = self.get_gt(frame_id)\n",
    "        return np.linalg.norm(curr_coords - prev_coords)\n",
    "\n",
    "    def get_sift_data(self, img, num_matches):\n",
    "        sift = cv2.SIFT_create(num_matches)\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        kp = np.array([k.pt for k in kp])\n",
    "        return kp, des\n",
    "    \n",
    "    def get_orb_data(self, img):\n",
    "        orb = cv2.ORB_create()\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        kp = np.array([k.pt for k in kp])\n",
    "        return kp, des\n",
    "\n",
    "    def plot_inlier_matches(self, ax, img1, img2, inliers):\n",
    "        res = np.hstack([img1, img2])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(res, cmap='gray')   \n",
    "        ax.plot(inliers[:,2], inliers[:,3], '+r')\n",
    "        ax.plot(inliers[:,0] + img1.shape[1], inliers[:,1], '+r')\n",
    "        ax.plot([inliers[:,2], inliers[:,0] + img1.shape[1]],\n",
    "                [inliers[:,3], inliers[:,1]], 'r', linewidth=0.4)\n",
    "        ax.axis('off')\n",
    "    def get_best_matches(self, img1, img2, num_matches):\n",
    "        #kp1, des1 = self.get_sift_data(img1, num_matches)\n",
    "        #kp2, des2 = self.get_sift_data(img2, num_matches)\n",
    "        kp1, des1 = self.get_orb_data(img1)\n",
    "        kp2, des2 = self.get_orb_data(img2)\n",
    "        dist = scipy.spatial.distance.cdist(des1, des2, 'sqeuclidean')\n",
    "        idx = np.argpartition(dist, num_matches, axis = None) #getting the first 100 lowest dist, flatten dist in the process\n",
    "        kp1_pos = idx[:num_matches]//kp2.shape[0] #retrieving kp1 from the flatten list\n",
    "        kp2_pos = idx[:num_matches]%kp2.shape[0] #retrieving kp2 from the flatten list\n",
    "        return np.hstack([kp2[kp2_pos],kp1[kp1_pos]])\n",
    "    \n",
    "    def bf_matcher(self, img1, img2, num_matches):\n",
    "        orb = cv2.ORB_create()\n",
    "        kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "        matches = bf.match(des1,des2)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        matches = matches[:num_matches]\n",
    "        list_kp1 = [kp1[mat.queryIdx].pt for mat in matches] \n",
    "        list_kp2 = [kp2[mat.trainIdx].pt for mat in matches]\n",
    "        return np.hstack([list_kp1, list_kp2])\n",
    "    \n",
    "    def update(self, last_image, current_image, scale):\n",
    "        self.img[\"current\"] = current_image\n",
    "        best_matches = self.get_best_matches(last_image, current_image, 2000)\n",
    "        #best_matches = self.bf_matcher(last_image, current_image, 2000)\n",
    "        q1 = best_matches[:, :2]\n",
    "        q2 = best_matches[:,2:]\n",
    "        E, mask = cv2.findEssentialMat(q1, q2,\n",
    "                                      focal = self.focal_length, pp = self.pp,\n",
    "                                      method = cv2.RANSAC, prob = 0.999, threshold = 1.0)\n",
    "        _, R,t, mask = cv2.recoverPose(E, q1, q2,\n",
    "                                      focal = self.focal_length, pp = self.pp)\n",
    "\n",
    "        a = (scale * self.current_R.dot(t)).reshape(3,1)\n",
    "        if (scale > 0.1):\n",
    "            self.current_t += a\n",
    "            self.current_R = R.dot(self.current_R)\n",
    "        self.img[\"last\"] = self.img[\"current\"]\n",
    "        return self.current_R, self.current_t\n",
    "    \n",
    "    def run(self):\n",
    "        ############### LOAD DATA #######################\n",
    "        num_images = len(self.pose)\n",
    "        predictions = np.zeros((num_images, 3))\n",
    "        spose = self.pose[0]\n",
    "        predictions[0] = np.vstack([np.array([float(spose[3]), float(spose[7]), float(spose[11])])])\n",
    "        for i in tqdm(range(num_images)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                last_img = self.imread(self.frames[i-1])\n",
    "                current_img = self.imread(self.frames[i])\n",
    "                R,t = self.update(last_img, current_img, self.get_scale(i))\n",
    "                pred = np.hstack([R,t]).reshape(-1,1)\n",
    "                predictions[i] = np.hstack([pred[3], pred[7], pred[11]])\n",
    "        np.save('predictions.npy', predictions)\n",
    "        print(\"prediction\", predictions)\n",
    "        ############## ODOMETRY ########################\n",
    "        \"\"\"\n",
    "        Uses the video frame to predict the path taken by the camera\n",
    "        \n",
    "        The reurned path should be a numpy array of shape nx3\n",
    "        n is the number of frames in the video  \n",
    "        \"\"\"\n",
    "        pred_coords = np.zeros((1,3))\n",
    "        for pose in self.pose[:num_images]:\n",
    "            pred_coords = np.vstack([pred_coords, np.array([float(pose[3]), float(pose[7]), float(pose[11])])])\n",
    "        gt = pred_coords[1:, :]\n",
    "        #print(gt)\n",
    "        \n",
    "        ############## EVALUATION #######################\n",
    "        with open('video_train/gt_sequence.txt', 'r') as f:\n",
    "            data = [line.strip().split() for line in f.readlines()]\n",
    "        path = np.load('./predictions.npy')\n",
    "        # Evaluation based on average mean squared error between the predicted\n",
    "        # coordinates and the ground truth coordinates\n",
    "        mse_scores = []\n",
    "        for pred_coord, pose in zip(path, data):\n",
    "            gt_coord = np.array([float(pose[3]), float(pose[7]), float(pose[11])])\n",
    "            mse_scores.append(np.linalg.norm(pred_coord - gt_coord))\n",
    "\n",
    "        # You can expect to get less than 40 MSE\n",
    "        mse_scores = np.mean(mse_scores)\n",
    "        print('avg_mse scores', mse_scores)\n",
    "        #################################################\n",
    "        return predictions\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    frame_path = 'video_train'\n",
    "    odemotryc = OdometryClass(frame_path)\n",
    "    path = odemotryc.run()\n",
    "    print(path,path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e92be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd73209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
