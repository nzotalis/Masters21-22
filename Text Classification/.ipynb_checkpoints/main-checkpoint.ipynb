{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af405bdf-692c-4957-b4fd-97d78906b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from catboost import CatBoostClassifier\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a384e0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0             I LOVE @Health4UandPets u guys r the best!! \n",
       " 1        im meeting up with one of my besties tonight! ...\n",
       " 2        @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       " 3        Being sick can be really cheap when it hurts t...\n",
       " 4          @LovesBrooklyn2 he has that effect on everyone \n",
       "                                ...                        \n",
       " 59995    best weekend ever; Caty Costigans house, Marle...\n",
       " 59996    Oh FFS! I've been here all fucking day. Why de...\n",
       " 59997    Leaving britney-just found out jon from new ki...\n",
       " 59998    @Neomic I havta' go pee, but Im scared to walk...\n",
       " 59999    Nooooooooooooooo!!!!!! School today. But the w...\n",
       " Name: text, Length: 60000, dtype: object,\n",
       " 0        1\n",
       " 1        1\n",
       " 2        1\n",
       " 3        1\n",
       " 4        1\n",
       "         ..\n",
       " 59995    0\n",
       " 59996    0\n",
       " 59997    0\n",
       " 59998    0\n",
       " 59999    0\n",
       " Name: sentiment, Length: 60000, dtype: int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_train_data = pd.read_csv(\"sentiment-train.csv\")\n",
    "sentiment_test_data = pd.read_csv(\"sentiment-test.csv\")\n",
    "train_x, train_y = sentiment_train_data[\"text\"], sentiment_train_data[\"sentiment\"]\n",
    "test_x, test_y = sentiment_test_data[\"text\"], sentiment_test_data[\"sentiment\"]\n",
    "train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bc009be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 529271 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstCv = CountVectorizer(max_features=1000)\n",
    "firstVectorizedTrain = firstCv.fit_transform(train_x)\n",
    "firstVectorizedTest = firstCv.transform(test_x)\n",
    "firstVectorizedTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2abbffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(firstVectorizedTrain, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c11c667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       177\n",
      "           1       0.71      0.79      0.75       182\n",
      "\n",
      "    accuracy                           0.73       359\n",
      "   macro avg       0.73      0.73      0.73       359\n",
      "weighted avg       0.73      0.73      0.73       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = mnb.predict(firstVectorizedTest)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d50033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cv = CountVectorizer(max_features = 1000, binary = True)\n",
    "binaryVectorizedTrain = binary_cv.fit_transform(train_x)\n",
    "binaryVectorizedTest = binary_cv.transform(test_x)\n",
    "binary_mnb = MultinomialNB()\n",
    "binary_mnb.fit(binaryVectorizedTrain, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3d78cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       177\n",
      "           1       0.71      0.80      0.75       182\n",
      "\n",
      "    accuracy                           0.74       359\n",
      "   macro avg       0.74      0.73      0.73       359\n",
      "weighted avg       0.74      0.74      0.73       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaryPreds = binary_mnb.predict(binaryVectorizedTest)\n",
    "print(classification_report(test_y, binaryPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "96e7bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.75       177\n",
      "           1       0.74      0.86      0.79       182\n",
      "\n",
      "    accuracy                           0.77       359\n",
      "   macro avg       0.78      0.77      0.77       359\n",
      "weighted avg       0.78      0.77      0.77       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter = 10**6)\n",
    "log_reg.fit(firstVectorizedTrain, train_y)\n",
    "logPreds = log_reg.predict(firstVectorizedTest)\n",
    "print(classification_report(test_y, logPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "61af2c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.67      0.73       177\n",
      "           1       0.72      0.85      0.78       182\n",
      "\n",
      "    accuracy                           0.76       359\n",
      "   macro avg       0.77      0.76      0.76       359\n",
      "weighted avg       0.77      0.76      0.76       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bin_log_reg = LogisticRegression(max_iter = 10**6)\n",
    "bin_log_reg.fit(binaryVectorizedTrain, train_y)\n",
    "binLogPreds = bin_log_reg.predict(binaryVectorizedTest)\n",
    "print(classification_report(test_y, binLogPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43792918",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10)\n",
    "for n_features in [1000, 2000, 3000, 4000]:\n",
    "    without_binary = 0\n",
    "    with_binary = 0\n",
    "    for train_index, test_index in skf.split(train_x, train_y):\n",
    "        vectorizer = CountVectorizer(max_features = n_features)\n",
    "        vectorizedTrain = vectorizer.fit_transform(train_x[train_index])\n",
    "        vectorizedTest = vectorizer.transform(train_x[test_index])\n",
    "        binVectorizer = CountVectorizer(max_features = n_features, binary = True)\n",
    "        binVectorizedTrain = binVectorizer.fit_transform(train_x[train_index])\n",
    "        binVectorizedTest = binVectorizer.transform(train_x[test_index])\n",
    "        \n",
    "        model = MultinomialNB()\n",
    "        model.fit(vectorizedTrain, train_y[train_index])\n",
    "        preds = model.predict(vectorizedTest)\n",
    "        without_binary += accuracy_score(train_y[test_index], preds)\n",
    "        \n",
    "        binModel = MultinomialNB()\n",
    "        binModel.fit(binVectorizedTrain, train_y[train_index])\n",
    "        preds = binModel.predict(binVectorizedTest)\n",
    "        with_binary += accuracy_score(train_y[test_index], preds)\n",
    "        \n",
    "    print(\"With %d features and not binary: %.3f\" % (n_features, without_binary / 10))\n",
    "    print(\"With %d features and binary: %.3f\" % (n_features, with_binary / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3bce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 4000, binary = True)\n",
    "vectorizedTrain = vectorizer.fit_transform(train_x)\n",
    "vectorizedTest = vectorizer.transform(test_x)\n",
    "model = MultinomialNB()\n",
    "model.fit(vectorizedTrain, train_y)\n",
    "preds = model.predict(vectorizedTest)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b14831-a82c-4b25-8bc2-d40a15091222",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def tokenize_tweet(x):\n",
    "    tokens = []\n",
    "    for sent in nlp(x).sents:\n",
    "        tokens += [str(token) for token in sent]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb5195-dbae-4845-8a9c-3e376c61b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgVec(model, sentence):\n",
    "    vec = 0\n",
    "    n = 0\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            vec += model.wv[word]\n",
    "            n += 1\n",
    "        except:\n",
    "            pass\n",
    "    if n != 0:\n",
    "        return vec / n\n",
    "    else:\n",
    "        return np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa80d10-fb71-4441-9543-56806e1f4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.split(\" \") for x in train_x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69cb77-1375-4b60-b34a-dd098776fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tokenized_train = []\n",
    "for i in tqdm(range(len(train_x))):\n",
    "    tokenized_train.append(tokenize_tweet(train_x[i]))\n",
    "    \n",
    "with open(\"w2v.txt\", \"wb\") as file:\n",
    "    pickle.dump(tokenized_train, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd718b3-3630-49dd-bb85-821adc9fa51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w2v.txt\", \"rb\") as file:\n",
    "    tokenized_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41f6db-9b6b-48d8-9dc0-281e2d6196c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_train, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf5d60-1a2b-4a5a-ab0a-7db6de80047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train = [avgVec(model, x) for x in tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784d2a3-7bb6-43b3-b9a4-2d08f69b3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(max_iter = 10**6)\n",
    "log.fit(vectorized_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf8015-06c9-4af4-b8da-7880ee5def6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test = [avgVec(model, tokenize_tweet(x)) for x in test_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea27fa8-fd22-4ded-81c3-3cb3ec7ad88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = log.predict(vectorized_test)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93084f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_tweets = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", header=None, usecols=[0, 5], encoding='latin-1')\n",
    "all_train_tweets = all_train_tweets[all_train_tweets[0] != 2]\n",
    "all_train_tweets.loc[all_train_tweets[0] == 4, 0] = 1 \n",
    "all_train_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfcdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_x = all_train_tweets[5]\n",
    "train_y = all_train_tweets[0]\n",
    "results = \"\"\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "for n_features in [1000, 2000, 3000, 4000]:\n",
    "    without_binary = 0\n",
    "    with_binary = 0\n",
    "    for train_index, test_index in skf.split(train_x, train_y):\n",
    "        vectorizer = CountVectorizer(max_features = n_features)\n",
    "        vectorizedTrain = vectorizer.fit_transform(train_x[train_index])\n",
    "        vectorizedTest = vectorizer.transform(train_x[test_index])\n",
    "        binVectorizer = CountVectorizer(max_features = n_features, binary = True)\n",
    "        binVectorizedTrain = binVectorizer.fit_transform(train_x[train_index])\n",
    "        binVectorizedTest = binVectorizer.transform(train_x[test_index])\n",
    "        \n",
    "        model = MultinomialNB()\n",
    "        model.fit(vectorizedTrain, train_y[train_index])\n",
    "        preds = model.predict(vectorizedTest)\n",
    "        without_binary += accuracy_score(train_y[test_index], preds)\n",
    "        \n",
    "        binModel = MultinomialNB()\n",
    "        binModel.fit(binVectorizedTrain, train_y[train_index])\n",
    "        preds = binModel.predict(binVectorizedTest)\n",
    "        with_binary += accuracy_score(train_y[test_index], preds)\n",
    "    result1 = \"With %d features and not binary: %.3f\" % (n_features, without_binary / 10)\n",
    "    result2 = \"With %d features and binary: %.3f\" % (n_features, with_binary / 10)\n",
    "    results += result1 + \"\\n\" + result2 + \"\\n\"\n",
    "    print(result1)\n",
    "    print(result2)\n",
    "\n",
    "with open(\"bonusResults.txt\", \"w\") as file:\n",
    "    file.write(results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e441934-39cf-4e74-aa33-7a41dd04600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bonusResults.txt\", \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7511d2-1415-430c-83b4-f31a353cd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training on the entire data set with 4000 and binary\n",
    "train_x = all_train_tweets[5]\n",
    "train_y = all_train_tweets[0]\n",
    "vectorizer = CountVectorizer(max_features = 4000, binary = True)\n",
    "model = MultinomialNB()\n",
    "train = vectorizer.fit_transform(train_x)\n",
    "test = vectorizer.transform(test_x)\n",
    "model.fit(train, train_y)\n",
    "preds = model.predict(test)\n",
    "print(classification_report(test_y, preds))\n",
    "#Slight increase to .79 accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb6de2-6e2f-4081-859f-dea7afb15941",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cv.get_feature_names()\n",
    "features[5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b12214-540e-4901-a33c-4e31908634e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodIndex = features.index('good')\n",
    "badIndex = features.index('bad')\n",
    "goodCoef = log_reg.coef_[0][goodIndex]\n",
    "badCoef = log_reg.coef_[0][badIndex]\n",
    "\n",
    "goodIndex, goodCoef, badIndex, badCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40eabf0-df00-4983-86b0-4653c57f5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most positive and most negative word\n",
    "features[np.argmax(log_reg.coef_[0])], max(log_reg.coef_[0]), features[np.argmin(log_reg.coef_[0])], min(log_reg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ca64f-253b-4d78-9dfa-8c7843caebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = sentiment_train_data[\"text\"], sentiment_train_data[\"sentiment\"]\n",
    "test_x, test_y = sentiment_test_data[\"text\"], sentiment_test_data[\"sentiment\"]\n",
    "model = CatBoostClassifier()\n",
    "model.fit(firstVectorizedTrain, train_y, verbose=False)\n",
    "train_preds = model.predict(firstVectorizedTrain)\n",
    "print(classification_report(train_y, train_preds))\n",
    "preds = model.predict(firstVectorizedTest)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1222204-bed2-4d75-9bc0-f641f12fe935",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model, feature_names=firstCv.get_feature_names())\n",
    "shap_values = explainer(firstVectorizedTrain)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b19429-19a5-4454-97e4-4ead55ad3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x[3])\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(firstVectorizedTrain)\n",
    "shap.plots.force(explainer.expected_value, shap_values[3], firstVectorizedTrain.toarray()[3], firstCv.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
