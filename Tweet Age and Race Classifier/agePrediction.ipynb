{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "code_start = time.time()\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orginal Dataset [Reading, Combining]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./labeled_users_1145/tweets.json\", encoding=\"utf8\") as file:\n",
    "    text = file.read()\n",
    "    tweets_1145 = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2678"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_1145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@_spacejamtwo THIRTY WHAT',\n",
       " 'I love my best friend https://t.co/f1fhHWmEK4',\n",
       " 'THANK YOU https://t.co/iGF1lyEWI0',\n",
       " '@_spacejamtwo I genuinely can not gage the size of you in this photo and it bothers me',\n",
       " '@hanpanmangaki IM SCREAMING THIS IS SO AMAZING!!!!!!!',\n",
       " 'OH MY GOD ITS ME!!!!!! LOOK AT HOW AMAZING THIS IS!!!!!!!! https://t.co/kgQJjgDNni',\n",
       " '@joonmoonchild @Scootsies ITS BEAUTIFUL',\n",
       " 'I am selling kf94 masks!!! Please dm me if you are interested!! Would appreciate rts 💖💖💖 https://t.co/sIpIrjXXlX',\n",
       " '@sukixtsuki 🥺💖',\n",
       " '@meixins THANKS MEI💖💖💖',\n",
       " '@sukixtsuki Islynyc on jnsta!!!!!!',\n",
       " 'These are real glasses and not a snapchat filter,, OKAY!? https://t.co/Dih01yzeLX',\n",
       " '@h0tcomedian Charge them double instead',\n",
       " 'My chris evans white sweater 🔪 https://t.co/3cr4DDfgiN',\n",
       " 'Its my best friends birthday!! https://t.co/T5gtX1kzNw',\n",
       " 'Im only here to upload selfies lmfaooooo https://t.co/T7xp5xctaI',\n",
       " '@joonmoonchild LMFMAOOS WHAT?!?!?',\n",
       " '@h0tcomedian THANKS GIRLLL',\n",
       " 'Bitch!!! I cut my own hair!! And look how well it turned out!!! https://t.co/uJgSetVJ9K',\n",
       " '@fairestbear LMFAOOO IRELANDDD',\n",
       " '@joonmoonchild 🥰🥰🥰',\n",
       " 'Im still here on this hellish app https://t.co/NaQA1K2Ojd',\n",
       " '@joonmoonchild BIIIITCH!!!!!!!!!!',\n",
       " '🍀🌷🌱 https://t.co/Djyh7pRERQ',\n",
       " 'https://t.co/8pW5k8ihWj https://t.co/2WwyFqKc5A',\n",
       " '@kelsonouveau @Scootsies OH MY GOD!!!!! THIS IS SO GOOD',\n",
       " '@jeanchloebae NOOOOOOOOO',\n",
       " '@jeanchloebae Fking universal and disney are both like this omfg',\n",
       " '@jeanchloebae OMG???/// OH MY GOD WHYYY?!?!?!?!?!??',\n",
       " '@meixins YOU CAN BOOKMARK EVERYONE ON AO3 😟😟😟😟😟😟 how is your computer not overheating?',\n",
       " '@meixins MEI,,, WHAT THE FUCK,,,,,,',\n",
       " '@andreylpatino 🥺🥺🥺🥺',\n",
       " '@fairestbear BABY GIRLLL💖💖💖💖💖',\n",
       " '@n0tmiki https://t.co/5L6IfYsjdw',\n",
       " 'if you look the right way, you can see that the whole world is a garden https://t.co/OJ5ceyICXX',\n",
       " 'My heart just dropped https://t.co/ZKdtPINcJC',\n",
       " '🌿🌿🌿🌿🌿 https://t.co/N9SC8p4spf',\n",
       " '@makdoongie KIA ARE U OKAY?',\n",
       " 'Sometimes the best part of tiktoks are the comments https://t.co/LdlNfdUxNu',\n",
       " '@jeanchloebae Everytime i see a korean with a small white dog, i just call them coco',\n",
       " 'dressed up for my besties wedding 💐☀️ https://t.co/RhEdicMc0H',\n",
       " 'He looks like milktpapi https://t.co/kHUneZZHWU',\n",
       " '@ghostliest Holy fucking shit bitch!!!!!!!!!!!!!!',\n",
       " 'The pants are jacquemus! I loved them, but they were the most ridiculous pants ive ever worn 💗',\n",
       " 'Old photoshoot 🌆 https://t.co/BAxEMtvv5g',\n",
       " '@_spacejamtwo THANK YOUUU',\n",
       " 'Wedding time~ https://t.co/4RaPSCg0dI',\n",
       " '@fairestbear I love you too💝💖💓💜💚❤💛🧡💗💖💕',\n",
       " '@fairestbear IRELAND MY SWEEET GIRL 🥺🥺🥺💖💖💖💖',\n",
       " 'Kylie jenner tipped $20 on a $500 bill and someone said \"i really think kylie thinks $20 means 20%\" LMAOOOOO']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_1145['strwbrrymlkt'][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_1145['___Dals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_1145 = pd.read_csv(\"./labeled_users_1145/labeled_users.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_1145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>protected</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>...</th>\n",
       "      <th>profile_background_url</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>user.name</th>\n",
       "      <th>num.tweets.used.Lexicon.prediction</th>\n",
       "      <th>Lexicon.age.prediction</th>\n",
       "      <th>Lexicon.gender.prediction..index.</th>\n",
       "      <th>lexicon.gender.prediction</th>\n",
       "      <th>human.labeled.gender</th>\n",
       "      <th>human.labeled.age</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>4.614412e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>zac ¢</td>\n",
       "      <td>Maryland, USA</td>\n",
       "      <td>_____Û___È_Ü´Ù</td>\n",
       "      <td>False</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1226134911...</td>\n",
       "      <td>@_____zac_____</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.652434</td>\n",
       "      <td>-1.457167</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>___aleia</td>\n",
       "      <td>7.650000e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>_æ___ dad ___æ_</td>\n",
       "      <td>Ohio, USA</td>\n",
       "      <td>BLACK. LIVES. MATTER.</td>\n",
       "      <td>False</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1271280679...</td>\n",
       "      <td>@___aleia</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.111464</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>___schaeffer___</td>\n",
       "      <td>1.257110e+09</td>\n",
       "      <td>en</td>\n",
       "      <td>Brenden Schaeffer</td>\n",
       "      <td>The Lou</td>\n",
       "      <td>Culver-Stockton College '20 ¢ Ô_Ô_Ô KM 1548...</td>\n",
       "      <td>False</td>\n",
       "      <td>811</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1268044218...</td>\n",
       "      <td>@___schaeffer___</td>\n",
       "      <td>59.0</td>\n",
       "      <td>35.518352</td>\n",
       "      <td>-3.591586</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>__drewc</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>drew</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>_öÂ_öé _öÂ_ö_ _ç´Ù È \\r\\r26 #NewYork</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1090809548...</td>\n",
       "      <td>@__drewc</td>\n",
       "      <td>134.0</td>\n",
       "      <td>24.910635</td>\n",
       "      <td>1.969121</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>__EmilyRice__</td>\n",
       "      <td>3.797155e+09</td>\n",
       "      <td>en</td>\n",
       "      <td>em</td>\n",
       "      <td>Marble Falls, TX</td>\n",
       "      <td>#TXST22</td>\n",
       "      <td>False</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8415201103...</td>\n",
       "      <td>@__EmilyRice__</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.191925</td>\n",
       "      <td>2.382856</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>3268</td>\n",
       "      <td>3269</td>\n",
       "      <td>zmeadows_18</td>\n",
       "      <td>7.050000e+17</td>\n",
       "      <td>und</td>\n",
       "      <td>Z Meadows</td>\n",
       "      <td>Circleville, OH</td>\n",
       "      <td>|OUCÈ23__|</td>\n",
       "      <td>False</td>\n",
       "      <td>556</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1252321514...</td>\n",
       "      <td>@zmeadows_18</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.385038</td>\n",
       "      <td>-1.729790</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>3271</td>\n",
       "      <td>3272</td>\n",
       "      <td>ZoeBerrier</td>\n",
       "      <td>9.020000e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Zoâ _êâ</td>\n",
       "      <td>Millersville, PA</td>\n",
       "      <td>MU 2021 (she/her)\\r\\rQueen of putting lipstick...</td>\n",
       "      <td>False</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1241199033...</td>\n",
       "      <td>@ZoeBerrier</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.585143</td>\n",
       "      <td>1.243141</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>3272</td>\n",
       "      <td>3273</td>\n",
       "      <td>ZoeCalamaco</td>\n",
       "      <td>3.214954e+09</td>\n",
       "      <td>no</td>\n",
       "      <td>Zoe _</td>\n",
       "      <td>San Angelo tx/ aspermont tx</td>\n",
       "      <td>Angelo state</td>\n",
       "      <td>False</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1277399838...</td>\n",
       "      <td>@ZoeCalamaco</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.348766</td>\n",
       "      <td>1.939069</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>3274</td>\n",
       "      <td>3275</td>\n",
       "      <td>ZoPeachy</td>\n",
       "      <td>9.890000e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Zobella Thee Alpha __ê_____´Ù__ ...</td>\n",
       "      <td>New England/Boston, MA</td>\n",
       "      <td>Harlot for hire. FinDom. 27. Nonbinary. they/t...</td>\n",
       "      <td>False</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1153648270...</td>\n",
       "      <td>@ZoPeachy</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.894953</td>\n",
       "      <td>2.058720</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>3279</td>\n",
       "      <td>3280</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>1.020000e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>_«_«ê_«__«ê</td>\n",
       "      <td>Moreno Valley, CA</td>\n",
       "      <td>i hate making bios oh my godddd UCIÈ21</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1221708547...</td>\n",
       "      <td>@zzzakari4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.257385</td>\n",
       "      <td>0.288805</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1145 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1      screen_name       user_id lang  \\\n",
       "0              0             1    _____zac_____  4.614412e+08   en   \n",
       "1              1             2         ___aleia  7.650000e+17   en   \n",
       "2              3             4  ___schaeffer___  1.257110e+09   en   \n",
       "3              8             9          __drewc  1.050000e+18   en   \n",
       "4              9            10    __EmilyRice__  3.797155e+09   en   \n",
       "...          ...           ...              ...           ...  ...   \n",
       "1140        3268          3269      zmeadows_18  7.050000e+17  und   \n",
       "1141        3271          3272       ZoeBerrier  9.020000e+17   en   \n",
       "1142        3272          3273      ZoeCalamaco  3.214954e+09   no   \n",
       "1143        3274          3275         ZoPeachy  9.890000e+17   en   \n",
       "1144        3279          3280        zzzakari4  1.020000e+18   en   \n",
       "\n",
       "                                                   name  \\\n",
       "0                                               zac ¢   \n",
       "1                                 _æ___ dad ___æ_   \n",
       "2                                     Brenden Schaeffer   \n",
       "3                                                  drew   \n",
       "4                                                    em   \n",
       "...                                                 ...   \n",
       "1140                                          Z Meadows   \n",
       "1141                                          Zoâ _êâ   \n",
       "1142                                           Zoe _   \n",
       "1143  Zobella Thee Alpha __ê_____´Ù__ ...   \n",
       "1144                                   _«_«ê_«__«ê   \n",
       "\n",
       "                         location  \\\n",
       "0                   Maryland, USA   \n",
       "1                       Ohio, USA   \n",
       "2                         The Lou   \n",
       "3                   New York, USA   \n",
       "4                Marble Falls, TX   \n",
       "...                           ...   \n",
       "1140              Circleville, OH   \n",
       "1141             Millersville, PA   \n",
       "1142  San Angelo tx/ aspermont tx   \n",
       "1143       New England/Boston, MA   \n",
       "1144            Moreno Valley, CA   \n",
       "\n",
       "                                            description  protected  \\\n",
       "0                                _____Û___È_Ü´Ù      False   \n",
       "1                                 BLACK. LIVES. MATTER.      False   \n",
       "2     Culver-Stockton College '20 ¢ Ô_Ô_Ô KM 1548...      False   \n",
       "3           _öÂ_öé _öÂ_ö_ _ç´Ù È \\r\\r26 #NewYork      False   \n",
       "4                                               #TXST22      False   \n",
       "...                                                 ...        ...   \n",
       "1140                                     |OUCÈ23__|      False   \n",
       "1141  MU 2021 (she/her)\\r\\rQueen of putting lipstick...      False   \n",
       "1142                                       Angelo state      False   \n",
       "1143  Harlot for hire. FinDom. 27. Nonbinary. they/t...      False   \n",
       "1144           i hate making bios oh my godddd UCIÈ21      False   \n",
       "\n",
       "      followers_count  ...                            profile_background_url  \\\n",
       "0                 208  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "1                 466  ...                                               NaN   \n",
       "2                 811  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "3                  27  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "4                 158  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "...               ...  ...                                               ...   \n",
       "1140              556  ...                                               NaN   \n",
       "1141               94  ...                                               NaN   \n",
       "1142              475  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "1143              396  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "1144               60  ...  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "\n",
       "                                      profile_image_url         user.name  \\\n",
       "0     http://pbs.twimg.com/profile_images/1226134911...    @_____zac_____   \n",
       "1     http://pbs.twimg.com/profile_images/1271280679...         @___aleia   \n",
       "2     http://pbs.twimg.com/profile_images/1268044218...  @___schaeffer___   \n",
       "3     http://pbs.twimg.com/profile_images/1090809548...          @__drewc   \n",
       "4     http://pbs.twimg.com/profile_images/8415201103...    @__EmilyRice__   \n",
       "...                                                 ...               ...   \n",
       "1140  http://pbs.twimg.com/profile_images/1252321514...      @zmeadows_18   \n",
       "1141  http://pbs.twimg.com/profile_images/1241199033...       @ZoeBerrier   \n",
       "1142  http://pbs.twimg.com/profile_images/1277399838...      @ZoeCalamaco   \n",
       "1143  http://pbs.twimg.com/profile_images/1153648270...         @ZoPeachy   \n",
       "1144  http://pbs.twimg.com/profile_images/1221708547...        @zzzakari4   \n",
       "\n",
       "     num.tweets.used.Lexicon.prediction  Lexicon.age.prediction  \\\n",
       "0                                 100.0               27.652434   \n",
       "1                                 100.0               24.111464   \n",
       "2                                  59.0               35.518352   \n",
       "3                                 134.0               24.910635   \n",
       "4                                 100.0               25.191925   \n",
       "...                                 ...                     ...   \n",
       "1140                              100.0               32.385038   \n",
       "1141                              100.0               22.585143   \n",
       "1142                              100.0               21.348766   \n",
       "1143                              100.0               34.894953   \n",
       "1144                              100.0               17.257385   \n",
       "\n",
       "     Lexicon.gender.prediction..index. lexicon.gender.prediction  \\\n",
       "0                            -1.457167                         M   \n",
       "1                             0.985713                         F   \n",
       "2                            -3.591586                         M   \n",
       "3                             1.969121                         F   \n",
       "4                             2.382856                         F   \n",
       "...                                ...                       ...   \n",
       "1140                         -1.729790                         M   \n",
       "1141                          1.243141                         F   \n",
       "1142                          1.939069                         F   \n",
       "1143                          2.058720                         F   \n",
       "1144                          0.288805                         F   \n",
       "\n",
       "     human.labeled.gender human.labeled.age  age  \n",
       "0                     NaN              23.0  1.0  \n",
       "1                     NaN              19.0  0.0  \n",
       "2                     NaN              22.0  0.0  \n",
       "3                     NaN              26.0  1.0  \n",
       "4                     NaN              20.0  0.0  \n",
       "...                   ...               ...  ...  \n",
       "1140                  NaN              19.0  0.0  \n",
       "1141                    F              20.0  0.0  \n",
       "1142                    F              21.0  0.0  \n",
       "1143                  NaN              27.0  1.0  \n",
       "1144                  NaN              21.0  0.0  \n",
       "\n",
       "[1145 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_1145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_1145[\"Under_21\"] = (users_1145[\"human.labeled.age\"] < 21 ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    718\n",
       "1    427\n",
       "Name: Under_21, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_1145[\"Under_21\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "list_of_screen_names = users_1145['screen_name'].unique()\n",
    "print(len(list_of_screen_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AdvoBarryRoux @GetVidBot</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The owner of drip doesn't even have 100 mill, ...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even Lekau the owner of Drip was saying that i...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@casspernyovest is cappin  that \"R100m\" figure...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want a recipe from @JBscotchSA for #JBLemona...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106309</th>\n",
       "      <td>uci fucking evil for making me go to school to...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>3279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106310</th>\n",
       "      <td>incredibly hot take, but i just think its funn...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>3279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106311</th>\n",
       "      <td>@valedesmadre u knw how i am 😫 its too much pr...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>3279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106312</th>\n",
       "      <td>will be needing a couple more business days to...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>3279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106313</th>\n",
       "      <td>its been 15 days since the final and ive final...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>3279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106314 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet    Screen Name  \\\n",
       "0                               @AdvoBarryRoux @GetVidBot  _____zac_____   \n",
       "1       The owner of drip doesn't even have 100 mill, ...  _____zac_____   \n",
       "2       even Lekau the owner of Drip was saying that i...  _____zac_____   \n",
       "3       @casspernyovest is cappin  that \"R100m\" figure...  _____zac_____   \n",
       "4       I want a recipe from @JBscotchSA for #JBLemona...  _____zac_____   \n",
       "...                                                   ...            ...   \n",
       "106309  uci fucking evil for making me go to school to...      zzzakari4   \n",
       "106310  incredibly hot take, but i just think its funn...      zzzakari4   \n",
       "106311  @valedesmadre u knw how i am 😫 its too much pr...      zzzakari4   \n",
       "106312  will be needing a couple more business days to...      zzzakari4   \n",
       "106313  its been 15 days since the final and ive final...      zzzakari4   \n",
       "\n",
       "        img_path  Under 21  \n",
       "0              0         0  \n",
       "1              0         0  \n",
       "2              0         0  \n",
       "3              0         0  \n",
       "4              0         0  \n",
       "...          ...       ...  \n",
       "106309      3279         0  \n",
       "106310      3279         0  \n",
       "106311      3279         0  \n",
       "106312      3279         0  \n",
       "106313      3279         0  \n",
       "\n",
       "[106314 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageDict = users_1145.set_index('screen_name').to_dict()['Under_21']\n",
    "imgPathDict = users_1145.set_index('screen_name').to_dict()['Unnamed: 0']\n",
    "\n",
    "tweetList, screenNameList, imgPathList, ageList = [], [], [], []\n",
    "\n",
    "for screen_name in tweets_1145:\n",
    "    \n",
    "    if((screen_name in list_of_screen_names)==False):\n",
    "        continue\n",
    "    for tweet in tweets_1145[screen_name]:\n",
    "        \n",
    "        tweetList.append(tweet)\n",
    "        \n",
    "        screenNameList.append(screen_name)\n",
    "        \n",
    "        imgPathList.append(imgPathDict[screen_name])\n",
    "        \n",
    "        ageList.append(ageDict[screen_name])\n",
    "        \n",
    "df_1 = pd.DataFrame({'Tweet': tweetList, 'Screen Name': screenNameList, 'img_path': imgPathList, 'Under 21': ageList})\n",
    "df_1.to_csv('labeled_tweet_table_Age.csv', index=False)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial=pd.read_csv('labeled_tweet_table_Age.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexMap={r\"<[\\w'/'\\s]*>\": \"\",r\"[\\'\\\"\\-]+\": \"\",r\"@[\\w]+\":\"\",r\"#[\\w]+\":\"\",\\\n",
    "          r\"https?:\\/\\/[\\w+@:%._\\+~#=]{1,256}\\.[\\w+()]{1,6}\\b([\\w+()@:%_\\+.~#?&\\/\\/=]*)\":\"\",\\\n",
    "          r\"https?:\\/\\/[\\w+@:%._\\+~#=]{1,256}\\.[\\w+()]{1,6}\\b([\\w+()@:%_\\+.~#?&\\/\\/=]*)\\b(\\;\\w+\\=\\w+)\":\"\",\\\n",
    "         r\"[\\w+@:%._\\+~#=]{1,256}\\.[\\w+()]{1,6}\\b([\\w+()@:%_\\+.~#?&\\/\\/=]*)\":\"\"}\n",
    "def preprocess(datainput):\n",
    "    t=datainput\n",
    "    for regx in regexMap.keys():\n",
    "        t = re.sub(regx, regexMap[regx], t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_initial[\"Tweet\"]=df_initial[\"Tweet\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_initial[[\"Tweet\",\"Screen Name\",\"Under 21\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The owner of drip doesnt even have 100 mill, d...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even Lekau the owner of Drip was saying that i...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is cappin  that R100m figure is so inflated, ...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want a recipe from  for ! If youre looking f...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106309</th>\n",
       "      <td>uci fucking evil for making me go to school to...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106310</th>\n",
       "      <td>incredibly hot take, but i just think its funn...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106311</th>\n",
       "      <td>u knw how i am 😫 its too much pressure to jus...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106312</th>\n",
       "      <td>will be needing a couple more business days to...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106313</th>\n",
       "      <td>its been 15 days since the final and ive final...</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet    Screen Name  \\\n",
       "0                                                          _____zac_____   \n",
       "1       The owner of drip doesnt even have 100 mill, d...  _____zac_____   \n",
       "2       even Lekau the owner of Drip was saying that i...  _____zac_____   \n",
       "3        is cappin  that R100m figure is so inflated, ...  _____zac_____   \n",
       "4       I want a recipe from  for ! If youre looking f...  _____zac_____   \n",
       "...                                                   ...            ...   \n",
       "106309  uci fucking evil for making me go to school to...      zzzakari4   \n",
       "106310  incredibly hot take, but i just think its funn...      zzzakari4   \n",
       "106311   u knw how i am 😫 its too much pressure to jus...      zzzakari4   \n",
       "106312  will be needing a couple more business days to...      zzzakari4   \n",
       "106313  its been 15 days since the final and ive final...      zzzakari4   \n",
       "\n",
       "        Under 21  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "106309         0  \n",
       "106310         0  \n",
       "106311         0  \n",
       "106312         0  \n",
       "106313         0  \n",
       "\n",
       "[106314 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.to_csv('Age_Tweets_Processed.csv', index=False)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    67044\n",
       "1    39270\n",
       "Name: Under 21, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Under 21'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_____zac_____' '___aleia' '___schaeffer___' '__drewc' '__EmilyRice__']\n",
      "1145\n"
     ]
    }
   ],
   "source": [
    "screen_names_list = df_2['Screen Name'].unique()\n",
    "\n",
    "print(screen_names_list[0:5])\n",
    "print(len(screen_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_classification_report(cr_list, cm_list):\n",
    "    n = len(cr_list)\n",
    "    acc, prec_0, rec_0, f1_0, prec_1, rec_1, f1_1 = 0, 0, 0, 0, 0, 0, 0\n",
    "    cm = np.zeros((2,2))\n",
    "    \n",
    "    for i,cr in enumerate(cr_list):\n",
    "        acc += cr['accuracy']\n",
    "        prec_0 += cr['0']['precision']\n",
    "        rec_0 += cr['0']['recall']\n",
    "        f1_0 += cr['0']['f1-score']\n",
    "        prec_1 += cr['1']['precision']\n",
    "        rec_1 += cr['1']['recall']\n",
    "        f1_1 += cr['1']['f1-score']\n",
    "        \n",
    "        cm += cm_list[i]\n",
    "    \n",
    "    print(\"Overall Accuracy-\",round(acc/n,3),\"\\n\")\n",
    "    print(\"------(Age >= 21)------\\n\")\n",
    "    print(\"Precision-\",round(prec_0/n,3))\n",
    "    print(\"Recall-\",round(rec_0/n,3))\n",
    "    print(\"F1-\",round(f1_0/n,3))\n",
    "    print(\"\\n------(Age < 21)------\\n\")\n",
    "    print(\"Precision-\",round(prec_1/n,3))\n",
    "    print(\"Recall-\",round(rec_1/n,3))\n",
    "    print(\"F1-\",round(f1_1/n,3))\n",
    "    print(\"\\nConfusion Matrix-\\n\",cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset [Concatenate strings for all users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_concat(screen_names,df):\n",
    "    tweets_dict = dict()\n",
    "\n",
    "    for i,screen_name in enumerate(screen_names):\n",
    "    \n",
    "        tweets_list = df[df['Screen Name']==screen_name][\"Tweet\"].tolist()\n",
    "        tweets_dict[i] = [screen_name,' '.join(tweets_list),df[df['Screen Name']==screen_name][\"Under 21\"].unique()[0]]\n",
    "    tweets_NB = pd.DataFrame.from_dict(tweets_dict , orient='index')\n",
    "    tweets_NB = tweets_NB.rename(columns={0: 'Screen Name', 1: 'Tweets', 2: 'Under 21'})\n",
    "    return tweets_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>The owner of drip doesnt even have 100 mill,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>___aleia</td>\n",
       "      <td>I haven’t talked to this girl since my sophomo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>___schaeffer___</td>\n",
       "      <td>☝🏼👋🏼       37149  congrats sis keep workin!!  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__drewc</td>\n",
       "      <td>Yo rly Try Cash App using my code and we’ll ea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__EmilyRice__</td>\n",
       "      <td>yes but come to san marcos and live with me 🥰...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>zmeadows_18</td>\n",
       "      <td>ROLL BOBBIES ROLL💚🖤💚🖤💚 We Are Texans! Im takin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>ZoeBerrier</td>\n",
       "      <td>Weve evolved past the need for those silly lit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>ZoeCalamaco</td>\n",
       "      <td>one person followed me // automatically checke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>ZoPeachy</td>\n",
       "      <td>Good morning! Say it back ♡  Happy Friday! Sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>i just know willows next album is gonna set me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Screen Name                                             Tweets  \\\n",
       "0       _____zac_____    The owner of drip doesnt even have 100 mill,...   \n",
       "1            ___aleia  I haven’t talked to this girl since my sophomo...   \n",
       "2     ___schaeffer___  ☝🏼👋🏼       37149  congrats sis keep workin!!  ...   \n",
       "3             __drewc  Yo rly Try Cash App using my code and we’ll ea...   \n",
       "4       __EmilyRice__   yes but come to san marcos and live with me 🥰...   \n",
       "...               ...                                                ...   \n",
       "1140      zmeadows_18  ROLL BOBBIES ROLL💚🖤💚🖤💚 We Are Texans! Im takin...   \n",
       "1141       ZoeBerrier  Weve evolved past the need for those silly lit...   \n",
       "1142      ZoeCalamaco  one person followed me // automatically checke...   \n",
       "1143         ZoPeachy  Good morning! Say it back ♡  Happy Friday! Sen...   \n",
       "1144        zzzakari4  i just know willows next album is gonna set me...   \n",
       "\n",
       "      Under 21  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "...        ...  \n",
       "1140         1  \n",
       "1141         1  \n",
       "1142         0  \n",
       "1143         0  \n",
       "1144         0  \n",
       "\n",
       "[1145 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat(screen_names_list,df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorizing(train_tweets_NB, test_tweets_NB,stop_words_vectorizer):\n",
    "    stop_words_vectorizer.fit(train_tweets_NB[\"Tweets\"].values)\n",
    "    \n",
    "    x_input=stop_words_vectorizer.transform(train_tweets_NB[\"Tweets\"].values)\n",
    "    x_test_input=stop_words_vectorizer.transform(test_tweets_NB[\"Tweets\"].values)\n",
    "    \n",
    "    return x_input, x_test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NB(train_tweets_NB, test_tweets_NB,nb,stop_words_vectorizer):\n",
    "    \n",
    "    x_input, x_test_input = Vectorizing(train_tweets_NB, test_tweets_NB,stop_words_vectorizer)\n",
    "    \n",
    "    nb.fit(x_input,train_tweets_NB[\"Under 21\"])\n",
    "    \n",
    "    y_pred_train = nb.predict(x_input)\n",
    "    print(\"Train accuracy-\",round(metrics.accuracy_score(train_tweets_NB[\"Under 21\"].values, y_pred_train),3))\n",
    "    \n",
    "    y_pred_test = nb.predict(x_test_input)\n",
    "    print(\"Test accuracy-\",round(metrics.accuracy_score(test_tweets_NB[\"Under 21\"].values, y_pred_test),3))\n",
    "    \n",
    "    c_report = classification_report(y_true=test_tweets_NB[\"Under 21\"].values,y_pred=y_pred_test,output_dict=True)\n",
    "    cm = confusion_matrix(test_tweets_NB[\"Under 21\"].values,y_pred_test)\n",
    "    \n",
    "    return c_report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold 1/5\n",
      "--------------------\n",
      "Train accuracy- 0.987\n",
      "Test accuracy- 0.646\n",
      "K-fold 2/5\n",
      "--------------------\n",
      "Train accuracy- 0.992\n",
      "Test accuracy- 0.716\n",
      "K-fold 3/5\n",
      "--------------------\n",
      "Train accuracy- 0.988\n",
      "Test accuracy- 0.703\n",
      "K-fold 4/5\n",
      "--------------------\n",
      "Train accuracy- 0.991\n",
      "Test accuracy- 0.62\n",
      "K-fold 5/5\n",
      "--------------------\n",
      "Train accuracy- 0.989\n",
      "Test accuracy- 0.655\n"
     ]
    }
   ],
   "source": [
    "df_nb = df_2\n",
    "screen_names_list = df_nb['Screen Name'].unique()\n",
    "\n",
    "kf_NB = KFold(n_splits=5, shuffle = True, random_state=24)\n",
    "c_report_list = []\n",
    "cm_list = []\n",
    "k=1\n",
    "\n",
    "stop_words_vectorizer=CountVectorizer(stop_words='english')\n",
    "\n",
    "for train_tweets_sn, test_tweets_sn in kf_NB.split(screen_names_list):\n",
    "    \n",
    "    print(f'K-fold {k}/{5}')\n",
    "    print('-' * 20)\n",
    "    \n",
    "    train_tweets_sn = screen_names_list[train_tweets_sn]\n",
    "    test_tweets_sn = screen_names_list[test_tweets_sn]\n",
    "    \n",
    "    train_tweets_NB = df_concat(train_tweets_sn,df_nb)\n",
    "    test_tweets_NB = df_concat(test_tweets_sn,df_nb)\n",
    "    \n",
    "    nb = MultinomialNB()\n",
    "    \n",
    "    a,b = model_NB(train_tweets_NB, test_tweets_NB,nb,stop_words_vectorizer)\n",
    "    \n",
    "    c_report_list.append(a)\n",
    "    cm_list.append(b)\n",
    "    \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for NB Model- 1.1 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken for NB Model-\",round((time.time()-NB_start)/60.0,2),\"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy- 0.668 \n",
      "\n",
      "------(Age >= 21)------\n",
      "\n",
      "Precision- 0.67\n",
      "Recall- 0.932\n",
      "F1- 0.779\n",
      "\n",
      "------(Age < 21)------\n",
      "\n",
      "Precision- 0.659\n",
      "Recall- 0.228\n",
      "F1- 0.335\n",
      "\n",
      "Confusion Matrix-\n",
      " [[669.  49.]\n",
      " [331.  96.]]\n"
     ]
    }
   ],
   "source": [
    "final_classification_report(c_report_list,cm_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFI DF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tfi_Df(train_tweets_NB, test_tweets_NB,tfidf):\n",
    "    \n",
    "    tfidf.fit(train_tweets_NB[\"Tweets\"])\n",
    "    \n",
    "    x_input=tfidf.transform(train_tweets_NB[\"Tweets\"])\n",
    "    x_test_input=tfidf.transform(test_tweets_NB[\"Tweets\"])\n",
    "    \n",
    "    return x_input, x_test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LR(train_tweets_NB, test_tweets_NB,log,tfidf):\n",
    "    \n",
    "    x_input, x_test_input = Tfi_Df(train_tweets_NB, test_tweets_NB,tfidf)\n",
    "    \n",
    "    log.fit(x_input,train_tweets_NB[\"Under 21\"])\n",
    "    \n",
    "    y_pred_train = log.predict(x_input)\n",
    "    print(\"Train accuracy-\",round(metrics.accuracy_score(train_tweets_NB[\"Under 21\"].values, y_pred_train),3))\n",
    "    \n",
    "    y_pred_test = log.predict(x_test_input)\n",
    "    print(\"Test accuracy-\",round(metrics.accuracy_score(test_tweets_NB[\"Under 21\"].values, y_pred_test),3))\n",
    "    \n",
    "    c_report = classification_report(y_true=test_tweets_NB[\"Under 21\"].values,y_pred=y_pred_test,output_dict=True)\n",
    "    cm = confusion_matrix(test_tweets_NB[\"Under 21\"].values,y_pred_test)\n",
    "    \n",
    "    return c_report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold 1/5\n",
      "--------------------\n",
      "Train accuracy- 0.98\n",
      "Test accuracy- 0.716\n",
      "K-fold 2/5\n",
      "--------------------\n",
      "Train accuracy- 0.976\n",
      "Test accuracy- 0.707\n",
      "K-fold 3/5\n",
      "--------------------\n",
      "Train accuracy- 0.975\n",
      "Test accuracy- 0.686\n",
      "K-fold 4/5\n",
      "--------------------\n",
      "Train accuracy- 0.977\n",
      "Test accuracy- 0.677\n",
      "K-fold 5/5\n",
      "--------------------\n",
      "Train accuracy- 0.98\n",
      "Test accuracy- 0.686\n"
     ]
    }
   ],
   "source": [
    "df_lr = df_2\n",
    "screen_names_list = df_lr['Screen Name'].unique()\n",
    "\n",
    "kf_LR = KFold(n_splits=5, shuffle = True, random_state=24)\n",
    "c_report_list = []\n",
    "cm_list = []\n",
    "k=1\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "for train_tweets_sn, test_tweets_sn in kf_LR.split(screen_names_list):\n",
    "    \n",
    "    print(f'K-fold {k}/{5}')\n",
    "    print('-' * 20)\n",
    "    \n",
    "    train_tweets_sn = screen_names_list[train_tweets_sn]\n",
    "    test_tweets_sn = screen_names_list[test_tweets_sn]\n",
    "    \n",
    "    train_tweets_NB = df_concat(train_tweets_sn,df_lr)\n",
    "    test_tweets_NB = df_concat(test_tweets_sn,df_lr)\n",
    "    \n",
    "    log = LogisticRegression(class_weight = 'balanced')\n",
    "    \n",
    "    a,b = model_LR(train_tweets_NB, test_tweets_NB,log,tfidf)\n",
    "    \n",
    "    c_report_list.append(a)\n",
    "    cm_list.append(b)\n",
    "    \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for LR Model- 1.11 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken for LR Model-\",round((time.time()-LR_start)/60.0,2),\"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy- 0.694 \n",
      "\n",
      "------(Age >= 21)------\n",
      "\n",
      "Precision- 0.742\n",
      "Recall- 0.786\n",
      "F1- 0.763\n",
      "\n",
      "------(Age < 21)------\n",
      "\n",
      "Precision- 0.601\n",
      "Recall- 0.542\n",
      "F1- 0.569\n",
      "\n",
      "Confusion Matrix-\n",
      " [[564. 154.]\n",
      " [196. 231.]]\n"
     ]
    }
   ],
   "source": [
    "final_classification_report(c_report_list,cm_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset [Split dataset by users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_BERT(tweets_sn, df):\n",
    "    tweets_df = df[df[\"Screen Name\"]==tweets_sn[0]]\n",
    "    for x in tweets_sn[1:]:\n",
    "        tweets_df = tweets_df.append(df[df[\"Screen Name\"]==x])\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 67044, 1: 39270})\n",
      "Resample dataset shape Counter({0: 67044, 1: 67044})\n"
     ]
    }
   ],
   "source": [
    "y = df_2['Under 21']\n",
    "\n",
    "ros = RandomOverSampler(random_state=24)\n",
    "df_resampled, y_ros = ros.fit_resample(df_2, y)\n",
    "\n",
    "print('Original dataset shape', Counter(y))\n",
    "print('Resample dataset shape', Counter(y_ros))\n",
    "\n",
    "df_resampled = pd.DataFrame(df_resampled, columns=df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    718\n",
       "1    427\n",
       "Name: Under 21, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat(screen_names_list,df_resampled)[\"Under 21\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet_Dataset(Dataset):\n",
    "    def __init__(self,dataset,tokenizer,max_len):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[\"Tweet\"])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tweet = str(self.dataset.iloc[index,0])\n",
    "        label = self.dataset.iloc[index,2]\n",
    "        \n",
    "        encoding_input = self.tokenizer.encode_plus(tweet,max_length=self.max_len, add_special_tokens=True,\\\n",
    "                                               return_token_type_ids=False,pad_to_max_length=True, return_attention_mask=True,\\\n",
    "                                               return_tensors='pt',truncation=True)\n",
    "        \n",
    "        \n",
    "        return {'tweet':tweet,'label':label,'input_ids':encoding_input['input_ids'].flatten(),\\\n",
    "                'attention_mask':encoding_input['attention_mask'].flatten()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "token_lens = []\n",
    "for txt in df_2[\"Tweet\"]:\n",
    "    tokens = tokenizer.encode(txt)\n",
    "    token_lens.append(len(tokens))\n",
    "print(max(token_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.bert_model=BertModel.from_pretrained(\"bert-base-cased\")\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.linear = nn.Linear(self.bert_model.config.hidden_size,2) \n",
    "        \n",
    "    def forward(self,input_ids, attention_mask):\n",
    "        \n",
    "        last_hidden_layer,pooled_output = self.bert_model(input_ids=input_ids,attention_mask=attention_mask, return_dict=False)\n",
    "        \n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        \n",
    "        linear_output = self.linear(dropout_output)\n",
    "        \n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer,device, scheduler):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    model=model.train()\n",
    "    losses=0 \n",
    "    accuracy=0 \n",
    "    \n",
    "    for d in dataloader:\n",
    "        \n",
    "        \n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['label'].to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Backpropagation\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        correct = (preds == targets).float()\n",
    "        acc=torch.sum(correct)\n",
    "        accuracy+=acc.item()  \n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        losses+=loss.item()   \n",
    "        \n",
    "    return accuracy/size, losses/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, device):\n",
    "    \n",
    "    model=model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            \n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "            targets = d['label'].to(device)\n",
    "        \n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            predictions = predictions + preds.tolist()\n",
    "    \n",
    "    values, counts = np.unique(predictions, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    final_pred = values[ind]\n",
    " \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_prediction(train_twitter_loader, test_tweets_df, test_tweets_sn, model, loss, optimizer, device, scheduler, \\\n",
    "                   epochs, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    best_test_acc = 0\n",
    "    c_report_best = None\n",
    "    c_matrix_best = None\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t + 1}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        start=time.time()\n",
    "                    \n",
    "        train_acc, train_loss = train_loop(train_twitter_loader, model, loss, optimizer, device, scheduler)\n",
    "\n",
    "        correct_pred = 0\n",
    "        \n",
    "        predictions=[]\n",
    "        target_values=[]\n",
    "        \n",
    "        for y in test_tweets_sn:\n",
    "            \n",
    "            test_dataset = Tweet_Dataset(test_tweets_df[test_tweets_df[\"Screen Name\"]==y],tokenizer,max_len)\n",
    "            test_twitter_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_pred = test_loop(test_twitter_loader, model, device)\n",
    "            \n",
    "            test_label = test_tweets_df[test_tweets_df[\"Screen Name\"]==y][\"Under 21\"].unique()\n",
    "            \n",
    "            if(test_pred==test_label[0]):\n",
    "                    correct_pred+=1\n",
    "            \n",
    "            predictions.append(test_pred)\n",
    "            target_values.append(test_label[0])\n",
    "        \n",
    "        end=time.time()\n",
    "        print(\"time taken-\",round((end-start)/60.0,2),\"minutes\")\n",
    "\n",
    "        print(\"Train Loss {} | Train Accuracy: {}%\".format(round(train_loss, 3), round(train_acc*100, 3)))\n",
    "        \n",
    "        test_acc = correct_pred/len(test_tweets_sn)\n",
    "        print(\"Test Accuracy: {}%\".format(round(test_acc*100, 3)))\n",
    "        \n",
    "        c_report = classification_report(y_true=target_values,y_pred=predictions,output_dict=True)\n",
    "        c_matrix = confusion_matrix(target_values,predictions)\n",
    "        \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            # Save the parameters of the model\n",
    "            c_report_best = c_report\n",
    "            c_matrix_best = c_matrix\n",
    "            \n",
    "    return c_report_best, c_matrix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_tweets_df, test_tweets_df, test_tweets_sn):\n",
    "    \n",
    "    learning_rate = 3.1e-5  \n",
    "    epochs = 4\n",
    "    \n",
    "    MAX_LEN = 160  \n",
    "    BATCH_SIZE = 64 \n",
    "\n",
    "    model = Classifier()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss=nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=3.1e-6)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "    \n",
    "    train_dataset = Tweet_Dataset(train_tweets_df,tokenizer,MAX_LEN)\n",
    "    train_twitter_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    total_steps = len(train_twitter_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=total_steps)\n",
    "    \n",
    "    return age_prediction(train_twitter_loader, test_tweets_df, test_tweets_sn, model, loss, optimizer, device, scheduler,\\\n",
    "                          epochs, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold 1/5\n",
      "--------------------\n",
      "Epoch 1/4\n",
      "----------\n",
      "time taken- 16.37 minutes\n",
      "Train Loss 0.01 | Train Accuracy: 59.652%\n",
      "Test Accuracy: 72.052%\n",
      "Epoch 2/4\n",
      "----------\n",
      "time taken- 16.38 minutes\n",
      "Train Loss 0.008 | Train Accuracy: 72.094%\n",
      "Test Accuracy: 71.616%\n",
      "Epoch 3/4\n",
      "----------\n",
      "time taken- 16.38 minutes\n",
      "Train Loss 0.006 | Train Accuracy: 82.275%\n",
      "Test Accuracy: 67.686%\n",
      "Epoch 4/4\n",
      "----------\n",
      "time taken- 16.38 minutes\n",
      "Train Loss 0.004 | Train Accuracy: 87.201%\n",
      "Test Accuracy: 69.869%\n",
      "K-fold 2/5\n",
      "--------------------\n",
      "Epoch 1/4\n",
      "----------\n",
      "time taken- 16.39 minutes\n",
      "Train Loss 0.01 | Train Accuracy: 60.133%\n",
      "Test Accuracy: 69.432%\n",
      "Epoch 2/4\n",
      "----------\n",
      "time taken- 16.41 minutes\n",
      "Train Loss 0.009 | Train Accuracy: 71.601%\n",
      "Test Accuracy: 70.306%\n",
      "Epoch 3/4\n",
      "----------\n",
      "time taken- 16.4 minutes\n",
      "Train Loss 0.006 | Train Accuracy: 81.778%\n",
      "Test Accuracy: 71.616%\n",
      "Epoch 4/4\n",
      "----------\n",
      "time taken- 16.4 minutes\n",
      "Train Loss 0.004 | Train Accuracy: 87.05%\n",
      "Test Accuracy: 72.926%\n",
      "K-fold 3/5\n",
      "--------------------\n",
      "Epoch 1/4\n",
      "----------\n",
      "time taken- 16.46 minutes\n",
      "Train Loss 0.01 | Train Accuracy: 60.574%\n",
      "Test Accuracy: 65.066%\n",
      "Epoch 2/4\n",
      "----------\n",
      "time taken- 16.47 minutes\n",
      "Train Loss 0.008 | Train Accuracy: 72.53%\n",
      "Test Accuracy: 66.812%\n",
      "Epoch 3/4\n",
      "----------\n",
      "time taken- 16.48 minutes\n",
      "Train Loss 0.006 | Train Accuracy: 81.99%\n",
      "Test Accuracy: 69.432%\n",
      "Epoch 4/4\n",
      "----------\n",
      "time taken- 16.46 minutes\n",
      "Train Loss 0.004 | Train Accuracy: 86.941%\n",
      "Test Accuracy: 67.686%\n",
      "K-fold 4/5\n",
      "--------------------\n",
      "Epoch 1/4\n",
      "----------\n",
      "time taken- 16.42 minutes\n",
      "Train Loss 0.01 | Train Accuracy: 60.473%\n",
      "Test Accuracy: 62.009%\n",
      "Epoch 2/4\n",
      "----------\n",
      "time taken- 16.43 minutes\n",
      "Train Loss 0.008 | Train Accuracy: 72.647%\n",
      "Test Accuracy: 65.502%\n",
      "Epoch 3/4\n",
      "----------\n",
      "time taken- 16.43 minutes\n",
      "Train Loss 0.006 | Train Accuracy: 82.684%\n",
      "Test Accuracy: 65.502%\n",
      "Epoch 4/4\n",
      "----------\n",
      "time taken- 16.44 minutes\n",
      "Train Loss 0.004 | Train Accuracy: 87.491%\n",
      "Test Accuracy: 65.066%\n",
      "K-fold 5/5\n",
      "--------------------\n",
      "Epoch 1/4\n",
      "----------\n",
      "time taken- 16.39 minutes\n",
      "Train Loss 0.01 | Train Accuracy: 60.666%\n",
      "Test Accuracy: 68.122%\n",
      "Epoch 2/4\n",
      "----------\n",
      "time taken- 16.4 minutes\n",
      "Train Loss 0.008 | Train Accuracy: 73.334%\n",
      "Test Accuracy: 66.812%\n",
      "Epoch 3/4\n",
      "----------\n",
      "time taken- 16.4 minutes\n",
      "Train Loss 0.006 | Train Accuracy: 83.058%\n",
      "Test Accuracy: 65.502%\n",
      "Epoch 4/4\n",
      "----------\n",
      "time taken- 16.4 minutes\n",
      "Train Loss 0.004 | Train Accuracy: 87.819%\n",
      "Test Accuracy: 66.812%\n"
     ]
    }
   ],
   "source": [
    "df = df_resampled\n",
    "screen_names_list = df['Screen Name'].unique()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=24)\n",
    "c_report_list = []\n",
    "cm_list = []\n",
    "k=1\n",
    "\n",
    "for train_tweets_sn, test_tweets_sn in kf.split(screen_names_list):\n",
    "    print(f'K-fold {k}/{5}')\n",
    "    print('-' * 20)\n",
    "    \n",
    "    train_tweets_sn = screen_names_list[train_tweets_sn]\n",
    "    test_tweets_sn = screen_names_list[test_tweets_sn]\n",
    "\n",
    "    train_tweets_df = df_BERT(train_tweets_sn, df)\n",
    "    test_tweets_df = df_BERT(test_tweets_sn, df)\n",
    "    c_report, c_matrix = main(train_tweets_df, test_tweets_df, test_tweets_sn)        \n",
    "    \n",
    "    c_report_list.append(c_report)\n",
    "    cm_list.append(c_matrix)\n",
    "    \n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for BERT Model- 5.49 hours\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken for BERT Model-\",round((time.time()-BERT_start)/3600.0,2),\"hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy- 0.696 \n",
      "\n",
      "------(Age >= 21)------\n",
      "\n",
      "Precision- 0.724\n",
      "Recall- 0.835\n",
      "F1- 0.773\n",
      "\n",
      "------(Age < 21)------\n",
      "\n",
      "Precision- 0.636\n",
      "Recall- 0.46\n",
      "F1- 0.526\n",
      "\n",
      "Confusion Matrix-\n",
      " [[600. 118.]\n",
      " [230. 197.]]\n"
     ]
    }
   ],
   "source": [
    "final_classification_report(c_report_list, cm_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for notebook- 5.54 hours\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken for notebook-\",round((time.time()-code_start)/3600.0,2),\"hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
