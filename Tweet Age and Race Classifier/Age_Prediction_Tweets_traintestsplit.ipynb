{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "code_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial=pd.read_csv('labeled_tweet_table_Age.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AdvoBarryRoux @GetVidBot</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The owner of drip doesn't even have 100 mill, ...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even Lekau the owner of Drip was saying that i...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@casspernyovest is cappin  that \"R100m\" figure...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want a recipe from @JBscotchSA for #JBLemona...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    Screen Name  img_path  \\\n",
       "0                          @AdvoBarryRoux @GetVidBot  _____zac_____         0   \n",
       "1  The owner of drip doesn't even have 100 mill, ...  _____zac_____         0   \n",
       "2  even Lekau the owner of Drip was saying that i...  _____zac_____         0   \n",
       "3  @casspernyovest is cappin  that \"R100m\" figure...  _____zac_____         0   \n",
       "4  I want a recipe from @JBscotchSA for #JBLemona...  _____zac_____         0   \n",
       "\n",
       "   Under 21  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106314, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexMap={r\"<[\\w'/'\\s]*>\": \"\",r\"[\\'\\\"\\-]+\": \"\",r\"@[\\w]+\":\"\",r\"#[\\w]+\":\"\",\\\n",
    "          r\"https?:\\/\\/[\\w+@:%._\\+~#=]{1,256}\\.[\\w+()]{1,6}\\b([\\w+()@:%_\\+.~#?&\\/\\/=]*)\":\"\",\\\n",
    "          r\"https?:\\/\\/[\\w+@:%._\\+~#=]{1,256}\\.[\\w+()]{1,6}\\b([\\w+()@:%_\\+.~#?&\\/\\/=]*)\\b(\\;\\w+\\=\\w+)\":\"\",\\\n",
    "         r\"[\\w+@:%._\\+~#=]{1,256}\\.[\\w+()]{1,6}\\b([\\w+()@:%_\\+.~#?&\\/\\/=]*)\":\"\"}\n",
    "def preprocess(datainput):\n",
    "    t=datainput\n",
    "    for regx in regexMap.keys():\n",
    "        t = re.sub(regx, regexMap[regx], t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial[\"Tweet\"]=df_initial[\"Tweet\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The owner of drip doesnt even have 100 mill, d...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even Lekau the owner of Drip was saying that i...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is cappin  that R100m figure is so inflated, ...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want a recipe from  for ! If youre looking f...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    Screen Name  img_path  \\\n",
       "0                                                     _____zac_____         0   \n",
       "1  The owner of drip doesnt even have 100 mill, d...  _____zac_____         0   \n",
       "2  even Lekau the owner of Drip was saying that i...  _____zac_____         0   \n",
       "3   is cappin  that R100m figure is so inflated, ...  _____zac_____         0   \n",
       "4  I want a recipe from  for ! If youre looking f...  _____zac_____         0   \n",
       "\n",
       "   Under 21  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106314, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_initial[[\"Tweet\",\"Screen Name\",\"Under 21\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The owner of drip doesnt even have 100 mill, d...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even Lekau the owner of Drip was saying that i...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is cappin  that R100m figure is so inflated, ...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want a recipe from  for ! If youre looking f...</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    Screen Name  Under 21\n",
       "0                                                     _____zac_____         1\n",
       "1  The owner of drip doesnt even have 100 mill, d...  _____zac_____         1\n",
       "2  even Lekau the owner of Drip was saying that i...  _____zac_____         1\n",
       "3   is cappin  that R100m figure is so inflated, ...  _____zac_____         1\n",
       "4  I want a recipe from  for ! If youre looking f...  _____zac_____         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106314, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56739\n",
       "1    49575\n",
       "Name: Under 21, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Under 21'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_____zac_____', '___aleia', '___schaeffer___', '__drewc', '__EmilyRice__']\n",
      "1145\n"
     ]
    }
   ],
   "source": [
    "screen_names_list = list(df['Screen Name'].unique())\n",
    "\n",
    "print(screen_names_list[0:5])\n",
    "print(len(screen_names_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset [Concatenate strings for all users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict = dict()\n",
    "\n",
    "for i,screen_name in enumerate(screen_names_list):\n",
    "    \n",
    "    tweets_list = df[df['Screen Name']==screen_name][\"Tweet\"].tolist()\n",
    "    tweets_dict[i] = [screen_name,' '.join(df[df['Screen Name']==screen_name][\"Tweet\"].tolist()),df[df['Screen Name']==screen_name][\"Under 21\"].unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_NB = pd.DataFrame.from_dict(tweets_dict , orient='index')\n",
    "tweets_NB = tweets_NB.rename(columns={0: 'Screen Name', 1: 'Tweets', 2: 'Under 21'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets_NB, test_tweets_NB = train_test_split(tweets_NB,train_size=0.8, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorizing(train_tweets_NB, test_tweets_NB,stop_words_vectorizer):\n",
    "    stop_words_vectorizer.fit(train_tweets_NB[\"Tweets\"].values)\n",
    "    \n",
    "    print(\"Number of words in Vocabulary-\",len(stop_words_vectorizer.vocabulary_))\n",
    "    \n",
    "    x_input=stop_words_vectorizer.transform(train_tweets_NB[\"Tweets\"].values)\n",
    "    x_test_input=stop_words_vectorizer.transform(test_tweets_NB[\"Tweets\"].values)\n",
    "    \n",
    "    return x_input, x_test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NB(train_tweets_NB, test_tweets_NB,nb,stop_words_vectorizer):\n",
    "\n",
    "    x_input, x_test_input = Vectorizing(train_tweets_NB, test_tweets_NB,stop_words_vectorizer)\n",
    "    nb.fit(x_input,train_tweets_NB[\"Under 21\"])\n",
    "    \n",
    "    y_pred_train = nb.predict(x_input)\n",
    "    print(\"Train accurary-\",metrics.accuracy_score(train_tweets_NB[\"Under 21\"].values, y_pred_train))\n",
    "    \n",
    "    y_pred_test = nb.predict(x_test_input)\n",
    "    print(\"Test accurary-\",metrics.accuracy_score(test_tweets_NB[\"Under 21\"].values, y_pred_test))\n",
    "    \n",
    "    print(\"Classification Report\\n\",classification_report(y_true=test_tweets_NB[\"Under 21\"].values,y_pred=y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_NB(train_tweets_NB, test_tweets_NB, tweets_NB):\n",
    "    nb = MultinomialNB()\n",
    "    stop_words_vectorizer=CountVectorizer(stop_words='english')\n",
    "    # model_NB(train_tweets_NB, test_tweets_NB,nb,stop_words_vectorizer)\n",
    "    KFold_model(nb, tweets_NB, stop_words_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def KFold_model(nb, tweets_NB, stop_words_vectorizer):\n",
    "    stop_words_vectorizer.fit(tweets_NB[\"Tweets\"].values)\n",
    "    print(\"Number of words in Vocabulary-\",len(stop_words_vectorizer.vocabulary_))\n",
    "    x_input = stop_words_vectorizer.transform(tweets_NB[\"Tweets\"].values)\n",
    "    y_pred = cross_val_predict(nb, x_input, tweets_NB[\"Under 21\"], cv=5)\n",
    "    print(\"Classification Report\\n\",classification_report(y_true=tweets_NB[\"Under 21\"].values,y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in Vocabulary- 38049\n",
      "Train accurary- 0.9748908296943232\n",
      "Test accurary- 0.6768558951965066\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73       122\n",
      "           1       0.73      0.50      0.59       107\n",
      "\n",
      "    accuracy                           0.68       229\n",
      "   macro avg       0.69      0.67      0.66       229\n",
      "weighted avg       0.69      0.68      0.67       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_NB(train_tweets_NB, test_tweets_NB, tweets_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset [Split dataset by users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets_sn, test_tweets_sn = train_test_split(screen_names_list,train_size=0.8, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916 229\n"
     ]
    }
   ],
   "source": [
    "print(len(train_tweets_sn),len(test_tweets_sn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74852</th>\n",
       "      <td>Gonna play Minecraft tonight! , cause I cant r...</td>\n",
       "      <td>holyheckitshope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74853</th>\n",
       "      <td>One of the runs Im watching on GDQs YouTube fe...</td>\n",
       "      <td>holyheckitshope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74854</th>\n",
       "      <td>More of Stardew Valley tonight! ☀🌊 Beach Farm!...</td>\n",
       "      <td>holyheckitshope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74855</th>\n",
       "      <td>Hayley I love yooooouuu  ☀🌊 Beach Farm! Fall, ...</td>\n",
       "      <td>holyheckitshope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74856</th>\n",
       "      <td>Didnt get a chance to say earlier when I retw...</td>\n",
       "      <td>holyheckitshope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>Going live on Twitch at 10:30pm est</td>\n",
       "      <td>SarcsmNMistakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40621</th>\n",
       "      <td>Watch us Live on Twitch\\n\\n</td>\n",
       "      <td>SarcsmNMistakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>Gonna stream tonight on twitch</td>\n",
       "      <td>SarcsmNMistakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40623</th>\n",
       "      <td>Subscribe to my YouTube channel as well! Thanks!</td>\n",
       "      <td>SarcsmNMistakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40624</th>\n",
       "      <td></td>\n",
       "      <td>SarcsmNMistakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84797 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet      Screen Name  \\\n",
       "74852  Gonna play Minecraft tonight! , cause I cant r...  holyheckitshope   \n",
       "74853  One of the runs Im watching on GDQs YouTube fe...  holyheckitshope   \n",
       "74854  More of Stardew Valley tonight! ☀🌊 Beach Farm!...  holyheckitshope   \n",
       "74855  Hayley I love yooooouuu  ☀🌊 Beach Farm! Fall, ...  holyheckitshope   \n",
       "74856   Didnt get a chance to say earlier when I retw...  holyheckitshope   \n",
       "...                                                  ...              ...   \n",
       "40620                Going live on Twitch at 10:30pm est  SarcsmNMistakes   \n",
       "40621                        Watch us Live on Twitch\\n\\n  SarcsmNMistakes   \n",
       "40622                     Gonna stream tonight on twitch  SarcsmNMistakes   \n",
       "40623   Subscribe to my YouTube channel as well! Thanks!  SarcsmNMistakes   \n",
       "40624                                                     SarcsmNMistakes   \n",
       "\n",
       "       Under 21  \n",
       "74852         1  \n",
       "74853         1  \n",
       "74854         1  \n",
       "74855         1  \n",
       "74856         1  \n",
       "...         ...  \n",
       "40620         1  \n",
       "40621         1  \n",
       "40622         1  \n",
       "40623         1  \n",
       "40624         1  \n",
       "\n",
       "[84797 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets_df = df[df[\"Screen Name\"]==train_tweets_sn[0]]\n",
    "for x in train_tweets_sn[1:]:\n",
    "    train_tweets_df = train_tweets_df.append(df[df[\"Screen Name\"]==x])\n",
    "train_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Under 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88895</th>\n",
       "      <td>I see u 👀</td>\n",
       "      <td>megannlindstrom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88896</th>\n",
       "      <td>The reason I have a crippling caffeine addicti...</td>\n",
       "      <td>megannlindstrom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88897</th>\n",
       "      <td>“Not gonna lie that tweet was kinda cheug” 😑</td>\n",
       "      <td>megannlindstrom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88898</th>\n",
       "      <td>I taught Adam the word “Cheugy” and he won’t s...</td>\n",
       "      <td>megannlindstrom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88899</th>\n",
       "      <td>Nothin like steppin out the gym and breathing ...</td>\n",
       "      <td>megannlindstrom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79543</th>\n",
       "      <td>2 &amp;amp; 3 🤍✨</td>\n",
       "      <td>Damarii_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79544</th>\n",
       "      <td>Amen 🙏🏼🤍✨</td>\n",
       "      <td>Damarii_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79545</th>\n",
       "      <td>both of our placements are in here hehe 🤍✨</td>\n",
       "      <td>Damarii_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79546</th>\n",
       "      <td>Affirmed and claimed this  thank you 🙏🏼🤍</td>\n",
       "      <td>Damarii_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79547</th>\n",
       "      <td>Reminder to wear a damn mask (:</td>\n",
       "      <td>Damarii_98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21517 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet      Screen Name  \\\n",
       "88895                                          I see u 👀  megannlindstrom   \n",
       "88896  The reason I have a crippling caffeine addicti...  megannlindstrom   \n",
       "88897       “Not gonna lie that tweet was kinda cheug” 😑  megannlindstrom   \n",
       "88898  I taught Adam the word “Cheugy” and he won’t s...  megannlindstrom   \n",
       "88899  Nothin like steppin out the gym and breathing ...  megannlindstrom   \n",
       "...                                                  ...              ...   \n",
       "79543                                       2 &amp; 3 🤍✨       Damarii_98   \n",
       "79544                                          Amen 🙏🏼🤍✨       Damarii_98   \n",
       "79545         both of our placements are in here hehe 🤍✨       Damarii_98   \n",
       "79546           Affirmed and claimed this  thank you 🙏🏼🤍       Damarii_98   \n",
       "79547                   Reminder to wear a damn mask (:        Damarii_98   \n",
       "\n",
       "       Under 21  \n",
       "88895         1  \n",
       "88896         1  \n",
       "88897         1  \n",
       "88898         1  \n",
       "88899         1  \n",
       "...         ...  \n",
       "79543         0  \n",
       "79544         0  \n",
       "79545         0  \n",
       "79546         0  \n",
       "79547         0  \n",
       "\n",
       "[21517 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets_df = df[df[\"Screen Name\"]==test_tweets_sn[0]]\n",
    "for x in test_tweets_sn[1:]:\n",
    "    test_tweets_df = test_tweets_df.append(df[df[\"Screen Name\"]==x])\n",
    "test_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84797, 3)\n",
      "(21517, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_tweets_df.shape)\n",
    "print(test_tweets_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    45349\n",
      "1    39448\n",
      "Name: Under 21, dtype: int64\n",
      "0    11390\n",
      "1    10127\n",
      "Name: Under 21, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_tweets_df[\"Under 21\"].value_counts())\n",
    "print(test_tweets_df[\"Under 21\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet_Dataset(Dataset):\n",
    "    def __init__(self,dataset,tokenizer,max_len):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[\"Tweet\"])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tweet = str(self.dataset.iloc[index,0])\n",
    "        label = self.dataset.iloc[index,2]\n",
    "        \n",
    "        encoding_input = self.tokenizer.encode_plus(tweet,max_length=self.max_len, add_special_tokens=True,\\\n",
    "                                               return_token_type_ids=False,pad_to_max_length=True, return_attention_mask=True,\\\n",
    "                                               return_tensors='pt',truncation=True)\n",
    "        \n",
    "        \n",
    "        return {'tweet':tweet,'label':label,'input_ids':encoding_input['input_ids'].flatten(),\\\n",
    "                'attention_mask':encoding_input['attention_mask'].flatten()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "token_lens = []\n",
    "for txt in df[\"Tweet\"]:\n",
    "    tokens = tokenizer.encode(txt)\n",
    "    token_lens.append(len(tokens))\n",
    "print(max(token_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.bert_model=BertModel.from_pretrained(\"bert-base-cased\")\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.linear = nn.Linear(self.bert_model.config.hidden_size,2) \n",
    "        \n",
    "    def forward(self,input_ids, attention_mask):\n",
    "        \n",
    "        last_hidden_layer,pooled_output = self.bert_model(input_ids=input_ids,attention_mask=attention_mask, return_dict=False)\n",
    "        \n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        \n",
    "        linear_output = self.linear(dropout_output)\n",
    "        \n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer,device, scheduler):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    model=model.train()\n",
    "    losses=0 \n",
    "    accuracy=0 \n",
    "    \n",
    "    for d in dataloader:\n",
    "        \n",
    "        \n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['label'].to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Backpropagation\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        correct = (preds == targets).float()\n",
    "        acc=torch.sum(correct)\n",
    "        accuracy+=acc.item()  \n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        losses+=loss.item()   \n",
    "        \n",
    "    return accuracy/size, losses/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, device):\n",
    "    \n",
    "    model=model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            \n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "            targets = d['label'].to(device)\n",
    "        \n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            predictions = predictions + preds.tolist()\n",
    "    \n",
    "    values, counts = np.unique(predictions, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    final_pred = values[ind]\n",
    " \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_prediction(train_twitter_loader, test_tweets_df, test_tweets_sn, model, loss, optimizer, device, scheduler, epochs, tokenizer, max_len, batch_size, test_twitter_loader):\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t + 1}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        start=time.time()\n",
    "                    \n",
    "        train_acc, train_loss = train_loop(train_twitter_loader, model, loss, optimizer, device, scheduler)\n",
    "\n",
    "        correct_pred = 0\n",
    "        \n",
    "        predictions=[]\n",
    "        target_values=[]\n",
    "        \n",
    "        for y in test_tweets_sn:\n",
    "            if test_twitter_loader is not None:\n",
    "                test_dataset = Tweet_Dataset(test_tweets_df[test_tweets_df[\"Screen Name\"]==y],tokenizer,max_len)\n",
    "                test_twitter_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_pred = test_loop(test_twitter_loader, model, device)\n",
    "            \n",
    "            test_label = test_tweets_df[test_tweets_df[\"Screen Name\"]==y][\"Under 21\"].unique()\n",
    "            \n",
    "            if(test_pred==test_label[0]):\n",
    "                    correct_pred+=1\n",
    "            \n",
    "            predictions.append(test_pred)\n",
    "            target_values.append(test_label[0])\n",
    "        \n",
    "        end=time.time()\n",
    "        print(\"time taken-\",round((end-start)/60.0,2),\"minutes\")\n",
    "\n",
    "        print(\"Train Loss {} | Train Accuracy: {}%\".format(round(train_loss, 3), round(train_acc*100, 3)))\n",
    "        \n",
    "        test_acc = correct_pred/len(test_tweets_sn)\n",
    "        print(\"Test Accuracy: {}%\".format(round(test_acc*100, 3)))\n",
    "        \n",
    "        print(\"Classification Report\\n\",classification_report(y_true=target_values,y_pred=predictions))\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            # Save the parameters of the model\n",
    "            torch.save(model.state_dict(), 'model_param.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_tweets_df, test_tweets_df, test_tweets_sn):\n",
    "    \n",
    "    learning_rate=3.1e-5  \n",
    "    epochs = 5\n",
    "    \n",
    "    MAX_LEN = 180  \n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "    model = Classifier()\n",
    "    model = model.to(device)\n",
    "\n",
    "    kfold=KFold(n_splits=5,shuffle=True)\n",
    "    \n",
    "    loss=nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "    \n",
    "    train_dataset = Tweet_Dataset(train_tweets_df,tokenizer,MAX_LEN)\n",
    "    train_twitter_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    dataset = Tweet_Dataset(screen_names_list, tokenizer, MAX_LEN)\n",
    "    \n",
    "    total_steps = len(train_twitter_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=total_steps)\n",
    "\n",
    "    for fold,(train_idx, test_idx) in enumerate(kfold.split(dataset)):\n",
    "        print('------------fold no---------{}----------------------'.format(fold))\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=BATCH_SIZE, sampler=test_subsampler)\n",
    "\n",
    "        model.apply(reset_weights)\n",
    "        \n",
    "        age_prediction(trainloader, test_tweets_df, test_tweets_sn, model, loss, optimizer, device, scheduler, epochs, tokenizer, MAX_LEN, BATCH_SIZE, testloader)\n",
    "    \n",
    "    # age_prediction(train_twitter_loader, test_tweets_df, test_tweets_sn, model, loss, optimizer, device, scheduler, epochs, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "time taken- 17.62 minutes\n",
      "Train Loss 0.042 | Train Accuracy: 58.756%\n",
      "Test Accuracy: 62.009%\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.73       122\n",
      "           1       0.88      0.21      0.35       107\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.74      0.60      0.54       229\n",
      "weighted avg       0.73      0.62      0.55       229\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "time taken- 17.49 minutes\n",
      "Train Loss 0.039 | Train Accuracy: 64.739%\n",
      "Test Accuracy: 66.376%\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.91      0.74       122\n",
      "           1       0.79      0.38      0.52       107\n",
      "\n",
      "    accuracy                           0.66       229\n",
      "   macro avg       0.71      0.65      0.63       229\n",
      "weighted avg       0.70      0.66      0.64       229\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "time taken- 17.49 minutes\n",
      "Train Loss 0.031 | Train Accuracy: 74.349%\n",
      "Test Accuracy: 74.672%\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       122\n",
      "           1       0.73      0.73      0.73       107\n",
      "\n",
      "    accuracy                           0.75       229\n",
      "   macro avg       0.75      0.75      0.75       229\n",
      "weighted avg       0.75      0.75      0.75       229\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "time taken- 17.5 minutes\n",
      "Train Loss 0.022 | Train Accuracy: 82.94%\n",
      "Test Accuracy: 69.432%\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69       122\n",
      "           1       0.65      0.77      0.70       107\n",
      "\n",
      "    accuracy                           0.69       229\n",
      "   macro avg       0.70      0.70      0.69       229\n",
      "weighted avg       0.70      0.69      0.69       229\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "time taken- 17.6 minutes\n",
      "Train Loss 0.017 | Train Accuracy: 87.505%\n",
      "Test Accuracy: 69.869%\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69       122\n",
      "           1       0.65      0.79      0.71       107\n",
      "\n",
      "    accuracy                           0.70       229\n",
      "   macro avg       0.71      0.70      0.70       229\n",
      "weighted avg       0.71      0.70      0.70       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(train_tweets_df, test_tweets_df, test_tweets_sn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_loop(test_tweets_df,model,device,test_tweets_sn, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    model=model.eval()\n",
    "    \n",
    "    predictions=[]\n",
    "    target_values=[]\n",
    "       \n",
    "    for y in test_tweets_sn:\n",
    "            \n",
    "        test_dataset = Tweet_Dataset(test_tweets_df[test_tweets_df[\"Screen Name\"]==y],tokenizer,max_len)\n",
    "        test_twitter_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_pred = test_loop(test_twitter_loader, model, device)\n",
    "\n",
    "        test_label = test_tweets_df[test_tweets_df[\"Screen Name\"]==y][\"Under 21\"].unique()\n",
    "\n",
    "        predictions.append(test_pred)\n",
    "        target_values.append(test_label[0])\n",
    "        \n",
    "    return predictions, target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = Classifier()\n",
    "model_pred.load_state_dict(torch.load('model_param.pt'))\n",
    "model_pred = model_pred.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "MAX_LEN = 180 \n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred,y=prediction_loop(test_tweets_df,model_pred,device, test_tweets_sn, tokenizer, MAX_LEN, BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       122\n",
      "           1       0.73      0.73      0.73       107\n",
      "\n",
      "    accuracy                           0.75       229\n",
      "   macro avg       0.75      0.75      0.75       229\n",
      "weighted avg       0.75      0.75      0.75       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "epochs = 5\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for notebook- 90.11\n"
     ]
    }
   ],
   "source": [
    "print(\"time taken for notebook-\",round((time.time()-code_start)/60.0,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
